name: SymPy Linear Solver Nightly

on:
  schedule:
    - cron: '15 2 * * *'   # nightly at 02:15 UTC
    - cron: '45 3 * * 0'   # weekly (Sunday) at 03:45 UTC
  workflow_dispatch:

jobs:
  nightly:
    runs-on: ubuntu-latest
    env:
      # Optional: provide the real NPZ via repository secret
      UK165_NPZ_URL: ${{ secrets.UK165_NPZ_URL }}
    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.11'

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install sympy numpy scipy pytest

      - name: Run PR-A unit tests (Cajal/Scheibel)
        if: always()
        shell: bash
        run: |
          set -euo pipefail
          export PYTHONPATH=.
          # Discover PR-A test files, if present
          TESTS=$(find vxor/benchmarks/tests -maxdepth 1 -type f \( -name 'test_arc_primitives.py' -o -name 'test_arc_registry.py' -o -name 'test_glue_features.py' -o -name 'test_glue_adapter_registry.py' \) 2>/dev/null || true)
          if [ -n "$TESTS" ]; then
            echo "[INFO] Running PR-A unit tests..."
            python -m pytest -q $TESTS
          else
            echo "[INFO] PR-A unit tests not found; skipping."
          fi

      - name: Run benchmark (real 165×165 via URL with offline fallback)
        id: run_bench
        env:
          UK165_NPZ_URL: ${{ secrets.UK165_NPZ_URL }}
          BENCH_SIZE: "165"
          OMP_NUM_THREADS: "1"
          MKL_NUM_THREADS: "1"
          OPENBLAS_NUM_THREADS: "1"
          PYTHONHASHSEED: "0"
        run: |
          set -euo pipefail
          OUT_DIR="${{ runner.temp }}/sympy_lin_results"
          mkdir -p "$OUT_DIR"
          python - <<'PY'
          import os, sys, json, time, hashlib, urllib.request
          from pathlib import Path
          import sympy as sp
          try:
              import numpy as np
          except Exception:
              np = None

          URL = os.getenv("UK165_NPZ_URL","").strip()
          N = int(os.getenv("BENCH_SIZE","165"))

          # Ziel-Dateiname anhand der URL-Endung
          ext = ""
          if URL:
              s = URL.split("?")[0]
              ext = s.rsplit(".",1)[-1].lower() if "." in s else ""
          PATH = f"bench_matrix.{ext or 'bin'}"

          def download(u, dst):
              for i in range(1,4):
                  try:
                      with urllib.request.urlopen(u, timeout=15) as r:
                          Path(dst).write_bytes(r.read()); return True
                  except Exception as e:
                      print(f"[warn] download {i}/3 failed: {e}")
                      time.sleep(2*i)
              return False

          def sha256_bytes(b: bytes)->str:
              h = hashlib.sha256(); h.update(b); return h.hexdigest()

          def vec_hash_det(vec, prec=12)->str:
              s = "|".join(f"{float(v):.{prec}g}" for v in vec)
              return hashlib.sha256(s.encode("utf-8")).hexdigest()

          A = b = None
          source = "synthetic"
          mat_sha = rhs_sha = None

          # 1) Versuche Download + Laden (NPZ bevorzugt, JSON Fallback)
          if URL and download(URL, PATH):
              source = "url"
              data_bytes = Path(PATH).read_bytes()
              mat_sha = sha256_bytes(data_bytes)
              if PATH.endswith(".npz") and np is not None:
                  data = np.load(PATH)
                  # Heuristik: NxN + N/ Nx1 finden
                  Akey = bkey = None
                  for k,v in data.items():
                      if getattr(v, "ndim", 0) == 2 and v.shape == (N,N): Akey = Akey or k
                      if getattr(v, "ndim", 0) in (1,2) and (v.shape[0] == N): bkey = bkey or k
                  if Akey is None or bkey is None:
                      keys = list(data.keys()); 
                      if len(keys) >= 2: Akey, bkey = keys[0], keys[1]
                      else: raise ValueError("NPZ enthält nicht genügend Arrays")
                  A = sp.Matrix(data[Akey].tolist())
                  b_arr = data[bkey]
                  b = sp.Matrix(b_arr.reshape(-1).tolist())
                  rhs_sha = mat_sha  # beides im Container
              else:
                  try:
                      d = json.loads(data_bytes.decode("utf-8"))
                      A = sp.Matrix(d["A"]); b = sp.Matrix(d["b"])
                  except Exception as e:
                      print(f"[warn] downloaded file not JSON/NPZ ({e}); using synthetic")
                      source = "synthetic"

          # 2) Synthetic Fallback
          if A is None or b is None:
              import random
              random.seed(42)
              A = sp.Matrix([[random.random() for _ in range(N)] for __ in range(N)])
              b = sp.Matrix([random.random() for _ in range(N)])

          # 3) Lösen & Metriken
          t0 = time.perf_counter()
          x = A.LUsolve(b)
          dt = time.perf_counter() - t0

          r = A*x - b
          residual_l2 = float(sp.sqrt(sum((float(v)**2 for v in r))))

          out = {
            "n": N,
            "method": "LUsolve",
            "solve_sec": round(dt, 6),
            "source": source,
            "residual_l2": residual_l2,
            "solution_sha256": vec_hash_det([x[i] for i in range(x.rows)]),
          }
          if mat_sha: out["matrix_sha256"] = mat_sha
          if rhs_sha: out["rhs_sha256"] = rhs_sha

          # Save results to both output directory and metrics file
          out_dir = os.getenv("OUT_DIR", ".")
          result_file = Path(out_dir) / "benchmark_result.json"
          result_file.write_text(json.dumps(out, indent=2))
          
          # Write metrics file for gates step
          metrics_file = Path("lin_solve_metrics.json")
          metrics_file.write_text(json.dumps(out, indent=2))
          
          print(json.dumps(out, indent=2))
          print(f"::set-output name=json_path::{result_file}")
          print(f"::set-output name=out_dir::{out_dir}")
          print(f"::set-output name=used_demo::{0 if source == 'url' else 1}")
          PY
          echo "OUT_DIR=$OUT_DIR" >> "$GITHUB_ENV"
          JSON_PATH="$OUT_DIR/benchmark_result.json"
          echo "JSON_PATH=$JSON_PATH" >> "$GITHUB_ENV"

      - name: Gates (residual, time, delta)
        run: |
          python - <<'PY'
          import json, sys, pathlib, math, os, time
          m = json.loads(pathlib.Path("lin_solve_metrics.json").read_text(encoding="utf-8"))
          errors = []

          # Hard gates (Nightly)
          if m.get("residual_l2", 1e9) > 1e-8:
              errors.append(f"residual_l2 too high: {m['residual_l2']:.3e} > 1e-8")
          if m.get("solve_sec", 1e9) > 120:
              errors.append(f"solve_sec too slow: {m['solve_sec']:.3f}s > 120s budget (nightly)")

          # Delta-Gate vs "last green" (optional: lege Datei im Repo ab)
          last_path = pathlib.Path("bench/lin_solve_last_green.json")
          if last_path.exists():
              last = json.loads(last_path.read_text(encoding="utf-8"))
              if m["solve_sec"] > last["solve_sec"] * 1.15:
                  errors.append(f"delta gate: {m['solve_sec']:.3f}s > +15% vs last green {last['solve_sec']:.3f}s")
          else:
              print("[info] no last_green available — delta gate skipped")

          if errors:
              print("GATES FAIL:\n - " + "\n - ".join(errors))
              sys.exit(1)
          print("GATES PASS")
          print(f"Performance: {m['solve_sec']:.3f}s, residual: {m['residual_l2']:.3e}")
          PY

      - name: Upload lin-solve metrics
        uses: actions/upload-artifact@v4
        with:
          name: sympy_lin_metrics
          path: lin_solve_metrics.json
          retention-days: 14

      - name: Upload results artifact (JSON + manifests)
        uses: actions/upload-artifact@v4
        with:
          name: sympy_lin_results
          path: ${{ steps.run_bench.outputs.out_dir }}
          if-no-files-found: error
